{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62bd56f8-834e-43da-9b65-9a4a9c4c97c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "sys.path.append('../')\n",
    "from meta_fusion.benchmarks import *\n",
    "from meta_fusion.methods import *\n",
    "from meta_fusion.models import *\n",
    "from meta_fusion.utils import *\n",
    "from meta_fusion.third_party import *\n",
    "from meta_fusion.synthetic_data import Prepare_synthetic_data\n",
    "from meta_fusion.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d653ba08-5e6a-4c41-9086-eaa7cea563e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed data parameters\n",
    "repetition=1\n",
    "seed=1\n",
    "scale=0\n",
    "\n",
    "# Data model parameters\n",
    "n = 2000\n",
    "[d1, d2] = dim_modalities = [2000, 400]\n",
    "dim_latent = [50, 30, 20]\n",
    "noise_ratios = [0.4, 0.3]\n",
    "trans_type = [\"linear\", \"linear\", \"quadratic\"]\n",
    "mod_prop = [0, 0, 1, 0]\n",
    "interactive_prop = 0\n",
    "\n",
    "# mod1_outs = [40, 60, 80, 100]\n",
    "# mod2_outs = [40, 60, 80, 100]\n",
    "\n",
    "mod1_outs = [0, 60, 80]\n",
    "mod2_outs = [0, 60, 80]\n",
    "combined_hiddens = [300,200,100]\n",
    "mod1_hiddens = mod2_hiddens = [128]\n",
    "\n",
    "# data parameters\n",
    "data_name = 'regression'\n",
    "exp_name = data_name + \"_\" + \"quadratic_late\"\n",
    "output_dim = 1  # specify the output dimension for regression\n",
    "\n",
    "\n",
    "extractor_type = 'encoder'\n",
    "separate=False\n",
    "is_static_mod1=False\n",
    "is_static_mod2=False\n",
    "freeze_extractor_mod1=False\n",
    "freeze_extractor_mod2=False\n",
    "\n",
    "# Load default model configurations \n",
    "config = load_config('../experiments_synthetic/config.json')\n",
    "extractor_config = load_config('../experiments_synthetic/config_extractor.json')\n",
    "\n",
    "# Model files directory\n",
    "ckpt_dir = f\"./checkpoints/{exp_name}/scale{scale}_seed{seed}/\"\n",
    "config['ckpt_dir'] = extractor_config['ckpt_dir'] = ckpt_dir\n",
    "\n",
    "# Update other training parameters\n",
    "config['divergence_weight_scale'] =  scale\n",
    "config['output_dim'] = extractor_config['output_dim'] = output_dim\n",
    "config[\"init_lr\"] = 0.001\n",
    "config[\"epochs\"] = 1\n",
    "extractor_config[\"init_lr\"] = 0.001\n",
    "extractor_config[\"epochs\"] = 1\n",
    "\n",
    "\n",
    "config[\"ensemble_methods\"]=[\n",
    "        \"simple_average\",\n",
    "        \"weighted_average\",\n",
    "        \"greedy_ensemble\"\n",
    "        ]\n",
    "config[\"rho_list\"]=[0]\n",
    "\n",
    "#####################\n",
    "#    Load Dataset   #\n",
    "#####################\n",
    "data_preparer = Prepare_synthetic_data(data_name = data_name, test_size = 0.2, val_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d07e136-cfbc-4f5d-900b-d300dd4de203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_experiment(config, extractor_config, n,\n",
    "                          random_state, \n",
    "                          run_oracle=False, run_coop=True, \n",
    "                          run_coop_linear=False, run_all_at_once=False):\n",
    "\n",
    "    config['random_state'] = random_state\n",
    "    extractor_config['random_state'] = random_state\n",
    "    res_list = []\n",
    "    best_rho = {}\n",
    "    cohort_pairs = {}\n",
    "    ens_idxs={}\n",
    "\n",
    "    #----------------#\n",
    "    # Split dataset  #\n",
    "    #----------------#\n",
    "    train_loader, val_loader, test_loader, oracle_train_loader, oracle_val_loader, oracle_test_loader =\\\n",
    "    data_preparer.get_data_loaders(n, trans_type=trans_type, mod_prop=mod_prop, \n",
    "                                   interactive_prop = interactive_prop,\n",
    "                                   dim_modalities=dim_modalities, dim_latent=dim_latent,\n",
    "                                   noise_ratios=noise_ratios, random_state=random_state)\n",
    "    # Get data info\n",
    "    data_info = data_preparer.get_data_info()\n",
    "    d1 = data_info[0]\n",
    "    d2 = data_info[1]\n",
    "    n = data_info[2]\n",
    "    n_train = data_info[3]\n",
    "    n_val = data_info[4]\n",
    "    n_test = data_info[5]\n",
    "\n",
    "    print(f\"Finished splitting {data_name} dataset. Data information are summarized below:\\n\"\n",
    "            f\"Modality 1 dimension: {d1}\\n\"\n",
    "            f\"Modality 2 dimension: {d2}\\n\"\n",
    "            f\"Data size: {n}\\n\"\n",
    "            f\"Train size: {n_train}\\n\"\n",
    "            f\"Val size: {n_val}\\n\"\n",
    "            f\"Test size: {n_test}\")\n",
    "    sys.stdout.flush() \n",
    "\n",
    "    #------------------#\n",
    "    # Benchmark models #\n",
    "    #------------------#\n",
    "    bm_extractor = Extractors([0, d1], [0,d2], d1, d2, train_loader, val_loader)\n",
    "    _ = bm_extractor.get_dummy_extractors()\n",
    "    bm_cohort = Cohorts(extractors=bm_extractor, combined_hidden_layers=combined_hiddens, output_dim=output_dim)\n",
    "\n",
    "    if run_oracle:\n",
    "        oracle_d1 = dim_latent[0]\n",
    "        oracle_d2 = dim_latent[1]+dim_latent[2]\n",
    "        oracle_extractor = Extractors([0, oracle_d1], [0, oracle_d2], oracle_d1, oracle_d2, oracle_train_loader, oracle_val_loader)\n",
    "        _ = oracle_extractor.get_dummy_extractors()\n",
    "        oracle_cohort = Cohorts(extractors=oracle_extractor, combined_hidden_layers=combined_hiddens, output_dim=output_dim)\n",
    "\n",
    "    #----------------------------#\n",
    "    # Proposed model: MetaJoint  #\n",
    "    #----------------------------#\n",
    "    meta_extractor = Extractors(mod1_outs, mod2_outs, d1, d2, train_loader, val_loader)\n",
    "    if extractor_type == 'encoder':\n",
    "        _ = meta_extractor.get_encoder_extractors(mod1_hiddens, mod2_hiddens, separate=separate, config=extractor_config)\n",
    "    elif extractor_type == 'PCA':\n",
    "        _ = meta_extractor.get_PCA_extractors()\n",
    "    meta_cohort = Cohorts(extractors=meta_extractor, combined_hidden_layers=combined_hiddens, output_dim=output_dim,\n",
    "                          is_static_mod1=is_static_mod1, is_static_mod2=is_static_mod2,\n",
    "                          freeze_extractor_mod1=freeze_extractor_mod1, freeze_extractor_mod2=freeze_extractor_mod2)\n",
    "\n",
    "\n",
    "    #------------------------------#\n",
    "    #  Train and test benchmarks   #\n",
    "    #------------------------------#\n",
    "    bm_models = bm_cohort.get_cohort_models()\n",
    "    _, bm_dims = bm_cohort.get_cohort_info()\n",
    "    bm = Benchmarks(config, bm_models, bm_dims, [train_loader, val_loader])\n",
    "    bm.train()\n",
    "    res = bm.test(test_loader)\n",
    "    res_list.append(res)\n",
    "    print(f\"Finished running basic benchmarks!\")\n",
    "    \n",
    "    if run_oracle:\n",
    "        oracle_config = config\n",
    "        oracle_config[\"init_lr\"] = 0.001\n",
    "        oracle_models = oracle_cohort.get_cohort_models()\n",
    "        _, oracle_dims = oracle_cohort.get_cohort_info()\n",
    "        oracle = Benchmarks(config, oracle_models, oracle_dims, [oracle_train_loader, oracle_val_loader])\n",
    "        oracle.train()\n",
    "        res = oracle.test(oracle_test_loader)\n",
    "        res = {f\"oracle_{key}\": value for key, value in res.items()}\n",
    "        res_list.append(res)\n",
    "        print(f\"Finished running oracle benchmarks!\")\n",
    "        \n",
    "    if run_coop:\n",
    "        bm_models = bm_cohort.get_cohort_models()\n",
    "        _, bm_dims = bm_cohort.get_cohort_info()    \n",
    "        coop = Coop(config, bm_models, bm_dims, [train_loader, val_loader])\n",
    "        coop.train()\n",
    "        res = coop.test(test_loader)\n",
    "        res_list.append(res)\n",
    "        best_rho['coop'] = coop.best_rho\n",
    "        print(f\"Finished running coop!\")\n",
    "\n",
    "    if run_coop_linear:\n",
    "        cooplinear = CoopLinear([train_loader, val_loader], rho_list=config['rho_list'])\n",
    "        cooplinear.train()\n",
    "        res = cooplinear.test(test_loader)\n",
    "        res_list.append(res)\n",
    "        print(f\"Finished running coop linear!\")\n",
    "\n",
    "    \n",
    "    #------------------------------#\n",
    "    #  Train and test MetaJoint   #\n",
    "    #------------------------------#\n",
    "    cohort_models = meta_cohort.get_cohort_models()\n",
    "    _, dim_pairs = meta_cohort.get_cohort_info()\n",
    "    metafuse = Trainer(config, cohort_models, [train_loader, val_loader])\n",
    "    metafuse.train() \n",
    "    res = metafuse.test(test_loader)\n",
    "    res_list.append(res)\n",
    "    \n",
    "    metafuse.train_ablation() \n",
    "    res = metafuse.test_ablation(test_loader)\n",
    "    res_list.append(res)\n",
    "    \n",
    "    best_rho['meta_learner'] = metafuse.best_rho\n",
    "    cohort_pairs['cohort'] = dim_pairs\n",
    "    cohort_pairs['indep_cohort'] = dim_pairs\n",
    "    if \"greedy_ensemble\" in config[\"ensemble_methods\"]:\n",
    "        ens_idxs['greedy_ensemble'] = metafuse.ens_idxs        \n",
    "    \n",
    "    print(f\"Finished running meta fusion!\")\n",
    "    \n",
    "    \n",
    "    if run_all_at_once:\n",
    "        cohort_models = meta_cohort.get_cohort_models()\n",
    "        config['epochs']=30\n",
    "        allin1 = Trainer_all_at_once(config, cohort_models, [train_loader, val_loader])\n",
    "        allin1.train()\n",
    "        res = allin1.test(test_loader)\n",
    "        res_list.append(res)\n",
    "        best_rho['all_at_once'] = allin1.best_rho\n",
    "        print(f\"Finished running meta fusion all in one model!\")\n",
    "\n",
    "    \n",
    "    results = []\n",
    "    for res in res_list:\n",
    "        for method, val in res.items():\n",
    "            results.append({'Method': method, 'Test_metric': val, \n",
    "                            'best_rho':best_rho.get(method), 'cohort_pairs':cohort_pairs.get(method),\n",
    "                            'ensemble_idxs': ens_idxs.get(method)})\n",
    "    \n",
    "\n",
    "    results = pd.DataFrame(results)\n",
    "\n",
    "    results['random_state']=random_state\n",
    "    results[\"d1\"] = d1\n",
    "    results[\"d2\"] = d2\n",
    "    results['n'] = n\n",
    "    results['n_train'] = n_train\n",
    "    results['n_val'] = n_val\n",
    "    results['n_test'] = n_test \n",
    "    results['scale'] = scale\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "399dbf31-33e0-4cae-a5dc-dc6dc14665d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with repetition 1...\n",
      "Finished splitting regression dataset. Data information are summarized below:\n",
      "Modality 1 dimension: 2000\n",
      "Modality 2 dimension: 400\n",
      "Data size: 2000\n",
      "Train size: 1280\n",
      "Val size: 320\n",
      "Test size: 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:01<00:00, 928.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training benchmark models...\n",
      "Training with disagreement penalty = 0\n",
      "\n",
      "Epoch: 1/1 - LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:02<00:00, 541.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_1: train loss: 180.765, train task loss: 180.765 - val loss: 129.376, val task loss: 129.376 [*] Best so far\n",
      "model_2: train loss: 178.988, train task loss: 178.988 - val loss: 114.404, val task loss: 114.404 [*] Best so far\n",
      "model_3: train loss: 200.411, train task loss: 200.411 - val loss: 104.654, val task loss: 104.654 [*] Best so far\n",
      "Finished training benchmark models!\n",
      "Method: (mod1), Test_MSE: 134.7310791015625\n",
      "Method: (mod2), Test_MSE: 147.7878875732422\n",
      "Method: (early_fusion), Test_MSE: 147.08448791503906\n",
      "Method: (late_fusion), Test_MSE: 129.3821258544922\n",
      "Finished running basic benchmarks!\n",
      "Start training student cohort...\n",
      "Training with disagreement penalty = 0\n",
      "\n",
      "Epoch: 1/1 - LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1280/1280 [00:08<00:00, 152.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_1: train loss: 154.208, train task loss: 154.208 - val loss: 110.078, val task loss: 110.078 [*] Best so far\n",
      "model_2: train loss: 151.313, train task loss: 151.313 - val loss: 110.494, val task loss: 110.494 [*] Best so far\n",
      "model_3: train loss: 154.951, train task loss: 154.951 - val loss: 110.940, val task loss: 110.940 [*] Best so far\n",
      "model_4: train loss: 150.588, train task loss: 150.588 - val loss: 112.007, val task loss: 112.007 [*] Best so far\n",
      "model_5: train loss: 185.704, train task loss: 185.704 - val loss: 109.613, val task loss: 109.613 [*] Best so far\n",
      "Finished training student cohort!\n",
      "Selecting the optimal disgreement penalty via cross-validation...\n",
      "Best rho: 0 with average task loss: 110.6265\n",
      "Done!\n",
      "Selecting greedy ensemble on the best cohort...\n",
      "Pruned 1 worst models, keeping 4 models\n",
      "Initial best models: [4, 0, 1] with losses: [tensor(109.6128, grad_fn=<MseLossBackward0>), tensor(110.0782, grad_fn=<MseLossBackward0>), tensor(110.4945, grad_fn=<MseLossBackward0>)]\n",
      "Done!\n",
      "Method: (simple_average), Test_MSE: 132.34616088867188\n",
      "Method: (weighted_average), Test_MSE: 132.2870635986328\n",
      "Method: (greedy_ensemble), Test_MSE: 128.91969299316406\n",
      "Method: (best_single), Test_MSE: 137.1869354248047\n",
      "Method: (cohort), Test_MSE: [140.25405883789062, 139.87057495117188, 140.0338134765625, 141.79640197753906, 137.1869354248047]\n",
      "Method: (simple_average), Test_MSE: 132.34616088867188\n",
      "Method: (weighted_average), Test_MSE: 132.2870635986328\n",
      "Method: (greedy_ensemble), Test_MSE: 128.91969299316406\n",
      "Method: (best_single), Test_MSE: 137.1869354248047\n",
      "Method: (cohort), Test_MSE: [140.25405883789062, 139.87057495117188, 140.0338134765625, 141.79640197753906, 137.1869354248047]\n",
      "Finished running meta fusion!\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "#  Run Experiments  #\n",
    "#####################\n",
    "results = []\n",
    "\n",
    "for i in range(1, repetition+1):\n",
    "    print(f'Running with repetition {i}...')\n",
    "    random_state = repetition * (seed-1) + i\n",
    "    set_random_seed(random_state)\n",
    "    \n",
    "    # Run experiment\n",
    "    tmp = run_single_experiment(config, extractor_config, n, run_oracle=False, run_coop=False, random_state=random_state)\n",
    "    \n",
    "    results.append(tmp)\n",
    "\n",
    "results = pd.concat(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c783a21-bc31-45cb-aaff-5b28cda7839b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Test_metric</th>\n",
       "      <th>best_rho</th>\n",
       "      <th>cohort_pairs</th>\n",
       "      <th>ensemble_idxs</th>\n",
       "      <th>random_state</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>n</th>\n",
       "      <th>n_train</th>\n",
       "      <th>n_val</th>\n",
       "      <th>n_test</th>\n",
       "      <th>scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mod1</td>\n",
       "      <td>134.731079</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>400</td>\n",
       "      <td>2000</td>\n",
       "      <td>1280</td>\n",
       "      <td>320</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mod2</td>\n",
       "      <td>147.787888</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>400</td>\n",
       "      <td>2000</td>\n",
       "      <td>1280</td>\n",
       "      <td>320</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>early_fusion</td>\n",
       "      <td>147.084488</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>400</td>\n",
       "      <td>2000</td>\n",
       "      <td>1280</td>\n",
       "      <td>320</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>late_fusion</td>\n",
       "      <td>129.382126</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>400</td>\n",
       "      <td>2000</td>\n",
       "      <td>1280</td>\n",
       "      <td>320</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>simple_average</td>\n",
       "      <td>132.346161</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>400</td>\n",
       "      <td>2000</td>\n",
       "      <td>1280</td>\n",
       "      <td>320</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>132.287064</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>400</td>\n",
       "      <td>2000</td>\n",
       "      <td>1280</td>\n",
       "      <td>320</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>greedy_ensemble</td>\n",
       "      <td>128.919693</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[4, 0, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>400</td>\n",
       "      <td>2000</td>\n",
       "      <td>1280</td>\n",
       "      <td>320</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>best_single</td>\n",
       "      <td>137.186935</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>400</td>\n",
       "      <td>2000</td>\n",
       "      <td>1280</td>\n",
       "      <td>320</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cohort</td>\n",
       "      <td>[140.25405883789062, 139.87057495117188, 140.0...</td>\n",
       "      <td>None</td>\n",
       "      <td>[(100, 40), (100, 0), (60, 40), (60, 0), (0, 40)]</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>400</td>\n",
       "      <td>2000</td>\n",
       "      <td>1280</td>\n",
       "      <td>320</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>indep_simple_average</td>\n",
       "      <td>132.346161</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>400</td>\n",
       "      <td>2000</td>\n",
       "      <td>1280</td>\n",
       "      <td>320</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>indep_weighted_average</td>\n",
       "      <td>132.287064</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>400</td>\n",
       "      <td>2000</td>\n",
       "      <td>1280</td>\n",
       "      <td>320</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>indep_greedy_ensemble</td>\n",
       "      <td>128.919693</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>400</td>\n",
       "      <td>2000</td>\n",
       "      <td>1280</td>\n",
       "      <td>320</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>indep_best_single</td>\n",
       "      <td>137.186935</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>400</td>\n",
       "      <td>2000</td>\n",
       "      <td>1280</td>\n",
       "      <td>320</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>indep_cohort</td>\n",
       "      <td>[140.25405883789062, 139.87057495117188, 140.0...</td>\n",
       "      <td>None</td>\n",
       "      <td>[(100, 40), (100, 0), (60, 40), (60, 0), (0, 40)]</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>400</td>\n",
       "      <td>2000</td>\n",
       "      <td>1280</td>\n",
       "      <td>320</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Method                                        Test_metric  \\\n",
       "0                     mod1                                         134.731079   \n",
       "1                     mod2                                         147.787888   \n",
       "2             early_fusion                                         147.084488   \n",
       "3              late_fusion                                         129.382126   \n",
       "4           simple_average                                         132.346161   \n",
       "5         weighted_average                                         132.287064   \n",
       "6          greedy_ensemble                                         128.919693   \n",
       "7              best_single                                         137.186935   \n",
       "8                   cohort  [140.25405883789062, 139.87057495117188, 140.0...   \n",
       "9     indep_simple_average                                         132.346161   \n",
       "10  indep_weighted_average                                         132.287064   \n",
       "11   indep_greedy_ensemble                                         128.919693   \n",
       "12       indep_best_single                                         137.186935   \n",
       "13            indep_cohort  [140.25405883789062, 139.87057495117188, 140.0...   \n",
       "\n",
       "   best_rho                                       cohort_pairs ensemble_idxs  \\\n",
       "0      None                                               None          None   \n",
       "1      None                                               None          None   \n",
       "2      None                                               None          None   \n",
       "3      None                                               None          None   \n",
       "4      None                                               None          None   \n",
       "5      None                                               None          None   \n",
       "6      None                                               None     [4, 0, 1]   \n",
       "7      None                                               None          None   \n",
       "8      None  [(100, 40), (100, 0), (60, 40), (60, 0), (0, 40)]          None   \n",
       "9      None                                               None          None   \n",
       "10     None                                               None          None   \n",
       "11     None                                               None          None   \n",
       "12     None                                               None          None   \n",
       "13     None  [(100, 40), (100, 0), (60, 40), (60, 0), (0, 40)]          None   \n",
       "\n",
       "    random_state    d1   d2     n  n_train  n_val  n_test  scale  \n",
       "0              1  2000  400  2000     1280    320     400      0  \n",
       "1              1  2000  400  2000     1280    320     400      0  \n",
       "2              1  2000  400  2000     1280    320     400      0  \n",
       "3              1  2000  400  2000     1280    320     400      0  \n",
       "4              1  2000  400  2000     1280    320     400      0  \n",
       "5              1  2000  400  2000     1280    320     400      0  \n",
       "6              1  2000  400  2000     1280    320     400      0  \n",
       "7              1  2000  400  2000     1280    320     400      0  \n",
       "8              1  2000  400  2000     1280    320     400      0  \n",
       "9              1  2000  400  2000     1280    320     400      0  \n",
       "10             1  2000  400  2000     1280    320     400      0  \n",
       "11             1  2000  400  2000     1280    320     400      0  \n",
       "12             1  2000  400  2000     1280    320     400      0  \n",
       "13             1  2000  400  2000     1280    320     400      0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8ef1bb4-b3d6-4af2-8ef1-9e9ec717faec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3db9a0f7-4cef-4b16-8cf9-6391f5936f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8ac31e8-a4e4-43ef-95ed-b49deb0f2b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.update([1,2,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f4ea754-de42-4338-a12f-cb242611f28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 5]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c33836b-e25e-483c-9d46-5761c6f818ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
